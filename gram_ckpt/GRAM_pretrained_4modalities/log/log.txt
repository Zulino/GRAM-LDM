12/17/2024 23:54:02 - INFO - __main__ -   ==================model_configs==================

12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_model_type : vast
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_itm_ratio : 0.1
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_frozen_vision : False
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_frozen_audio : False
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_checkpointing : True
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_max_caption_len : 40
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_max_omni_caption_len : 70
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_max_subtitle_len : 70
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_contra_dim : 512
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_inherit_keys : ['vision_encoder_type', 'audio_encoder_type', 'audio_melbins', 'audio_target_length']
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_frame_embedding_type : adaptive
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_vision_resolution : 224
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_vision_encoder_type : evaclip01_giant
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_audio_encoder_type : beats
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_audio_melbins : 64
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_audio_target_length : 1024
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_beam_size : 3
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_captioner_mode : False
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_generate_nums : 1
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_ret_bidirection_evaluation : True
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_itm_rerank_num : 50
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_evaluation_type : evaluation_mm
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_default : ./config/vast/default_model_cfg.json
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_max_vision_sample_num : 8
12/17/2024 23:54:02 - INFO - __main__ -   model_cfg_max_audio_sample_num : 1
12/17/2024 23:54:02 - INFO - __main__ -   ==================run_configs==================

12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_checkpoint : 
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_output_dir : ./prove
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_gradient_accumulation_steps : 1
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_clip_lr : 5e-07
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_optim : adamw
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_learning_rate : 2e-05
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_betas : [0.9, 0.98]
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_weight_decay : 0.01
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_grad_norm : 2.0
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_warmup_ratio : 0.1
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_resume : False
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_seed : 50
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_fp16 : True
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_bf16 : False
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_zero_shot : False
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_scheduler : warmup_linear
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_new_lr : 0
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_new_params_name : []
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_valid_freq : 10
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_dataset_mix_type : random
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_remove_before_ckpt : True
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_first_eval : True
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_pretrain_dir : ./output/vast/pretrain_vast/downstream/finetuneVolume256batchlossonlyvolume4Mod120k/
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_num_train_steps : 0
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_save_best : True
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_pin_mem : True
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_vision_resolution : 224
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_use_ddp : False
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_mode : testing
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_log_steps : 100
12/17/2024 23:54:02 - INFO - __main__ -   run_cfg_default : ./config/vast/default_run_cfg.json
12/17/2024 23:54:02 - INFO - __main__ -   ==================data_configs==================

12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_type : annoindexed
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_training : True
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_name : msrvtt_ret
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_txt : datasets/annotations/msrvtt/descs_ret_train.json
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_vision : /leonardo_scratch/fast/IscrC_NeuroGen/dataset/MSRVTT/videos_train
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_audio : /leonardo_scratch/fast/IscrC_NeuroGen/dataset/MSRVTT/audios_train
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_vision_transforms : crop_flip
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_vision_format : video_rawvideo
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_vision_sample_num : 8
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_audio_sample_num : 1
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_task : ret%tv%ta
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_epoch : 4
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_n_workers : 8
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_train_batch_size : 64
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_type : annoindexed
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_training : False
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_name : msrvtt_ret
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_txt : datasets/annotations/msrvtt/descs_ret_test.json
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision : /leonardo_scratch/fast/IscrC_NeuroGen/dataset/MSRVTT/videos_test
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_transforms : crop_flip
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_format : video_rawvideo
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_audio : /leonardo_scratch/fast/IscrC_NeuroGen/dataset/MSRVTT/audios_test
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_sample_num : 8
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_audio_sample_num : 1
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_task : ret%tva%tvas
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_n_workers : 8
12/17/2024 23:54:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_batch_size : 64
12/17/2024 23:57:42 - INFO - __main__ -   load_from_pretrained: ./output/vast/pretrain_vast/downstream/finetuneVolume256batchlossonlyvolume4Mod120k/ckpt/model_step_459.pt
12/17/2024 23:57:42 - INFO - __main__ -   Load from pretrained dir ./output/vast/pretrain_vast/downstream/finetuneVolume256batchlossonlyvolume4Mod120k/
12/17/2024 23:57:43 - INFO - __main__ -   Unexpected keys []
12/17/2024 23:57:43 - INFO - __main__ -   missing_keys  ['roberta.0.auto_model.embeddings.word_embeddings.weight', 'roberta.0.auto_model.embeddings.position_embeddings.weight', 'roberta.0.auto_model.embeddings.token_type_embeddings.weight', 'roberta.0.auto_model.embeddings.LayerNorm.weight', 'roberta.0.auto_model.embeddings.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.0.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.0.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.0.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.0.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.0.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.0.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.0.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.0.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.0.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.0.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.0.output.dense.weight', 'roberta.0.auto_model.encoder.layer.0.output.dense.bias', 'roberta.0.auto_model.encoder.layer.0.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.0.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.1.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.1.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.1.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.1.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.1.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.1.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.1.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.1.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.1.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.1.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.1.output.dense.weight', 'roberta.0.auto_model.encoder.layer.1.output.dense.bias', 'roberta.0.auto_model.encoder.layer.1.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.1.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.2.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.2.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.2.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.2.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.2.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.2.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.2.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.2.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.2.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.2.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.2.output.dense.weight', 'roberta.0.auto_model.encoder.layer.2.output.dense.bias', 'roberta.0.auto_model.encoder.layer.2.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.2.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.3.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.3.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.3.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.3.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.3.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.3.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.3.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.3.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.3.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.3.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.3.output.dense.weight', 'roberta.0.auto_model.encoder.layer.3.output.dense.bias', 'roberta.0.auto_model.encoder.layer.3.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.3.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.4.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.4.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.4.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.4.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.4.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.4.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.4.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.4.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.4.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.4.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.4.output.dense.weight', 'roberta.0.auto_model.encoder.layer.4.output.dense.bias', 'roberta.0.auto_model.encoder.layer.4.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.4.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.5.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.5.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.5.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.5.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.5.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.5.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.5.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.5.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.5.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.5.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.5.output.dense.weight', 'roberta.0.auto_model.encoder.layer.5.output.dense.bias', 'roberta.0.auto_model.encoder.layer.5.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.5.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.6.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.6.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.6.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.6.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.6.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.6.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.6.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.6.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.6.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.6.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.6.output.dense.weight', 'roberta.0.auto_model.encoder.layer.6.output.dense.bias', 'roberta.0.auto_model.encoder.layer.6.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.6.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.7.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.7.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.7.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.7.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.7.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.7.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.7.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.7.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.7.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.7.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.7.output.dense.weight', 'roberta.0.auto_model.encoder.layer.7.output.dense.bias', 'roberta.0.auto_model.encoder.layer.7.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.7.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.8.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.8.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.8.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.8.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.8.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.8.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.8.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.8.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.8.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.8.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.8.output.dense.weight', 'roberta.0.auto_model.encoder.layer.8.output.dense.bias', 'roberta.0.auto_model.encoder.layer.8.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.8.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.9.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.9.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.9.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.9.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.9.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.9.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.9.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.9.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.9.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.9.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.9.output.dense.weight', 'roberta.0.auto_model.encoder.layer.9.output.dense.bias', 'roberta.0.auto_model.encoder.layer.9.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.9.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.10.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.10.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.10.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.10.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.10.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.10.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.10.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.10.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.10.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.10.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.10.output.dense.weight', 'roberta.0.auto_model.encoder.layer.10.output.dense.bias', 'roberta.0.auto_model.encoder.layer.10.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.10.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.11.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.11.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.11.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.11.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.11.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.11.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.11.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.11.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.11.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.11.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.11.output.dense.weight', 'roberta.0.auto_model.encoder.layer.11.output.dense.bias', 'roberta.0.auto_model.encoder.layer.11.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.11.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.12.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.12.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.12.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.12.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.12.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.12.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.12.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.12.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.12.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.12.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.12.output.dense.weight', 'roberta.0.auto_model.encoder.layer.12.output.dense.bias', 'roberta.0.auto_model.encoder.layer.12.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.12.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.13.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.13.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.13.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.13.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.13.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.13.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.13.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.13.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.13.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.13.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.13.output.dense.weight', 'roberta.0.auto_model.encoder.layer.13.output.dense.bias', 'roberta.0.auto_model.encoder.layer.13.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.13.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.14.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.14.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.14.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.14.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.14.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.14.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.14.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.14.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.14.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.14.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.14.output.dense.weight', 'roberta.0.auto_model.encoder.layer.14.output.dense.bias', 'roberta.0.auto_model.encoder.layer.14.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.14.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.15.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.15.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.15.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.15.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.15.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.15.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.15.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.15.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.15.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.15.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.15.output.dense.weight', 'roberta.0.auto_model.encoder.layer.15.output.dense.bias', 'roberta.0.auto_model.encoder.layer.15.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.15.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.16.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.16.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.16.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.16.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.16.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.16.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.16.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.16.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.16.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.16.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.16.output.dense.weight', 'roberta.0.auto_model.encoder.layer.16.output.dense.bias', 'roberta.0.auto_model.encoder.layer.16.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.16.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.17.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.17.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.17.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.17.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.17.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.17.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.17.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.17.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.17.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.17.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.17.output.dense.weight', 'roberta.0.auto_model.encoder.layer.17.output.dense.bias', 'roberta.0.auto_model.encoder.layer.17.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.17.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.18.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.18.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.18.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.18.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.18.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.18.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.18.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.18.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.18.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.18.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.18.output.dense.weight', 'roberta.0.auto_model.encoder.layer.18.output.dense.bias', 'roberta.0.auto_model.encoder.layer.18.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.18.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.19.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.19.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.19.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.19.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.19.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.19.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.19.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.19.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.19.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.19.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.19.output.dense.weight', 'roberta.0.auto_model.encoder.layer.19.output.dense.bias', 'roberta.0.auto_model.encoder.layer.19.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.19.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.20.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.20.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.20.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.20.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.20.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.20.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.20.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.20.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.20.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.20.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.20.output.dense.weight', 'roberta.0.auto_model.encoder.layer.20.output.dense.bias', 'roberta.0.auto_model.encoder.layer.20.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.20.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.21.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.21.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.21.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.21.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.21.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.21.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.21.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.21.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.21.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.21.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.21.output.dense.weight', 'roberta.0.auto_model.encoder.layer.21.output.dense.bias', 'roberta.0.auto_model.encoder.layer.21.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.21.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.22.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.22.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.22.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.22.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.22.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.22.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.22.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.22.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.22.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.22.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.22.output.dense.weight', 'roberta.0.auto_model.encoder.layer.22.output.dense.bias', 'roberta.0.auto_model.encoder.layer.22.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.22.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.23.attention.self.query.weight', 'roberta.0.auto_model.encoder.layer.23.attention.self.query.bias', 'roberta.0.auto_model.encoder.layer.23.attention.self.key.weight', 'roberta.0.auto_model.encoder.layer.23.attention.self.key.bias', 'roberta.0.auto_model.encoder.layer.23.attention.self.value.weight', 'roberta.0.auto_model.encoder.layer.23.attention.self.value.bias', 'roberta.0.auto_model.encoder.layer.23.attention.output.dense.weight', 'roberta.0.auto_model.encoder.layer.23.attention.output.dense.bias', 'roberta.0.auto_model.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.0.auto_model.encoder.layer.23.intermediate.dense.weight', 'roberta.0.auto_model.encoder.layer.23.intermediate.dense.bias', 'roberta.0.auto_model.encoder.layer.23.output.dense.weight', 'roberta.0.auto_model.encoder.layer.23.output.dense.bias', 'roberta.0.auto_model.encoder.layer.23.output.LayerNorm.weight', 'roberta.0.auto_model.encoder.layer.23.output.LayerNorm.bias', 'roberta.0.auto_model.pooler.dense.weight', 'roberta.0.auto_model.pooler.dense.bias']
12/17/2024 23:57:44 - INFO - __main__ -   msrvtt_ret Using clip mean and std.
12/17/2024 23:57:44 - INFO - __main__ -   msrvtt_ret transforms crop_flip
12/17/2024 23:57:44 - INFO - __main__ -   Create Dataset msrvtt_ret Success
12/17/2024 23:57:44 - INFO - __main__ -   evaluate on ret%tva%tvas--msrvtt_ret task
12/17/2024 23:57:44 - INFO - __main__ -   start running ret%tva%tvas validation...
12/18/2024 00:01:15 - INFO - __main__ -   ==== evaluation--ret%tva%tvas--msrvtt_ret_gramian_value========

12/18/2024 00:01:15 - INFO - __main__ -   {'value': 0.825873076915741}
12/18/2024 00:01:15 - INFO - __main__ -   ==== evaluation--ret%tva%tvas--msrvtt_ret_ret_area_forward========

12/18/2024 00:01:15 - INFO - __main__ -   {'volume_T2D_r1': 40.4, 'volume_T2D_recall': '40.4/66.9/75.6', 'volume_T2D_ravg': 60.9}
12/18/2024 00:01:15 - INFO - __main__ -   ==== evaluation--ret%tva%tvas--msrvtt_ret_ret_area_backard========

12/18/2024 00:01:15 - INFO - __main__ -   {'forward_r1': 36.5, 'forward_recall': '36.5/65.4/76.4', 'forward_ravg': 59.4}
12/18/2024 00:01:15 - INFO - __main__ -   ==== evaluation--ret%tva%tvas--msrvtt_ret_ret_itm_area========

12/18/2024 00:01:15 - INFO - __main__ -   {'volume_ITM_T2D_r1': 54.8, 'volume_ITM_T2D_recall': '54.8/75.7/83.6', 'volume_ITM_T2D_ravg': 71.3, 'volume_ITM_D2T_r1': 52.9, 'volume_ITM_D2T_recall': '52.9/76.0/82.9', 'volume_ITM_D2T_ravg': 70.6}
12/18/2024 00:01:15 - INFO - __main__ -   ==== evaluation--ret%tva%tvas--msrvtt_ret_cosine_TV========

12/18/2024 00:01:15 - INFO - __main__ -   {'forward_r1': 42.9, 'forward_recall': '42.9/71.2/81.2', 'forward_ravg': 65.1}
12/18/2024 00:01:15 - INFO - __main__ -   ==== evaluation--ret%tva%tvas--msrvtt_ret_cosine_VT========

12/18/2024 00:01:15 - INFO - __main__ -   {'forward_r1': 37.1, 'forward_recall': '37.1/64.8/75.1', 'forward_ravg': 59.0}
12/18/2024 00:01:15 - INFO - __main__ -   ==== evaluation--ret%tva%tvas--msrvtt_ret_cosine_TA========

12/18/2024 00:01:15 - INFO - __main__ -   {'forward_r1': 7.2, 'forward_recall': '7.2/19.2/26.0', 'forward_ravg': 17.5}
12/18/2024 00:01:15 - INFO - __main__ -   ==== evaluation--ret%tva%tvas--msrvtt_ret_cosine_AT========

12/18/2024 00:01:15 - INFO - __main__ -   {'forward_r1': 5.8, 'forward_recall': '5.8/16.5/24.5', 'forward_ravg': 15.6}
